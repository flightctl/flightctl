name: 'Deploy Backend with Helm'
description: |
  Complete deployment of FlightCtl backend to a kind cluster using Helm.
  
  Downloads artifacts (images, chart, CLI), creates kind cluster, loads images,
  and deploys using helm.

inputs:
  tag:
    description: 'Image tag for artifacts (if not provided, will be computed from git)'
    required: false
  base-domain:
    description: 'Base domain for the deployment'
    required: true
  namespace-external:
    description: 'External namespace for FlightCtl API components'
    required: false
    default: 'flightctl-external'
  namespace-internal:
    description: 'Internal namespace for FlightCtl backend components'
    required: false
    default: 'flightctl-internal'
  additional-values-files:
    description: 'Space-separated list of additional Helm values files to apply (paths relative to repo root)'
    required: false
    default: ''
  auth-type:
    description: 'Authentication type (empty for default, "k8s" for Kubernetes auth)'
    required: false
    default: ''
  kind-config:
    description: 'Path to kind cluster config file'
    required: false
    default: 'deploy/kind.yaml'
  display-summary:
    description: 'Whether to display deployment summary in GitHub step summary'
    required: false
    default: 'true'
  wait:
    description: 'Wait for deployment to complete (adds --wait --debug to helm install)'
    required: false
    default: 'true'
  flavor:
    description: 'Container flavor (el9 or el10)'
    required: false
    default: 'el9'

runs:
  using: "composite"
  steps:
    # ========== COMPUTE TAGS IF NOT PROVIDED ==========
    - name: Compute tags from git
      id: compute-tags-git
      if: inputs.tag == ''
      uses: ./.github/actions/compute-tag

    - name: Set git tag
      id: compute-tags
      shell: bash
      run: |
        set -euo pipefail

        if [ -n "${{ inputs.tag }}" ]; then
          echo "Using provided tag: ${{ inputs.tag }}"
          TAG="${{ inputs.tag }}"
          echo "git_tag=${TAG}" >> "$GITHUB_OUTPUT"

          # Also set helm_tag (normalize by dropping leading v, replace ~ with -)
          HELM_TAG=$(echo "${TAG#v}" | sed 's/~/-/g')
          echo "helm_tag=${HELM_TAG}" >> "$GITHUB_OUTPUT"
        else
          echo "Using computed tags from git action"
          echo "git_tag=${{ steps.compute-tags-git.outputs.git_tag }}" >> "$GITHUB_OUTPUT"
          echo "helm_tag=${{ steps.compute-tags-git.outputs.helm_tag }}" >> "$GITHUB_OUTPUT"
        fi

    # ========== DOWNLOAD BACKEND ARTIFACTS ==========
    - name: Download backend images bundle
      id: download-images
      continue-on-error: true
      uses: actions/download-artifact@v4
      with:
        name: flightctl-images-bundle-${{ inputs.flavor }}-${{ steps.compute-tags.outputs.git_tag }}
        path: artifacts

    - name: Download helm chart
      id: download-chart
      continue-on-error: true
      uses: actions/download-artifact@v4
      with:
        name: helm-chart-${{ inputs.flavor }}-${{ steps.compute-tags.outputs.git_tag }}
        path: artifacts

    - name: Download CLI binary
      id: download-cli
      continue-on-error: true
      uses: actions/download-artifact@v4
      with:
        name: flightctl-linux-amd64-${{ inputs.flavor }}-${{ steps.compute-tags.outputs.git_tag }}
        path: artifacts

    # ========== DEBUG: CHECK DOWNLOAD OUTCOMES ==========
    - name: Debug download outcomes and artifacts
      shell: bash
      run: |
        echo "=== DOWNLOAD OUTCOMES DEBUG ==="
        echo "Images download outcome: ${{ steps.download-images.outcome }}"
        echo "Chart download outcome: ${{ steps.download-chart.outcome }}"
        echo "CLI download outcome: ${{ steps.download-cli.outcome }}"
        echo ""
        echo "Available artifacts:"
        ls -la artifacts/ 2>/dev/null || echo "No artifacts directory found"
        echo ""
        echo "Artifacts directory contents by type:"
        find artifacts/ -name "flightctl-images-bundle*" 2>/dev/null || echo "No image bundle found"
        find artifacts/ -name "flightctl-chart*" 2>/dev/null || echo "No chart found"
        find artifacts/ -name "flightctl-linux-amd64*" 2>/dev/null || echo "No CLI binary found"
        echo ""
        echo "Which fallback builds will trigger?"
        if [ "${{ steps.download-images.outcome }}" == "failure" ]; then
          echo "‚ùå Image fallback build WILL trigger"
        else
          echo "‚úÖ Image fallback build will NOT trigger"
        fi
        if [ "${{ steps.download-chart.outcome }}" == "failure" ]; then
          echo "‚ùå Chart fallback build WILL trigger"
        else
          echo "‚úÖ Chart fallback build will NOT trigger"
        fi
        if [ "${{ steps.download-cli.outcome }}" == "failure" ]; then
          echo "‚ùå CLI fallback build WILL trigger"
        else
          echo "‚úÖ CLI fallback build will NOT trigger"
        fi
        echo "========================"

    # ========== FALLBACK: BUILD LOCAL ARTIFACTS IF DOWNLOADS FAILED ==========
    - name: Build local containers if artifacts not available
      if: steps.download-images.outcome == 'failure'
      shell: bash
      env:
        FLAVOR: ${{ inputs.flavor }}
      run: |
        echo "::group::Building local containers for $FLAVOR"
        echo "‚ùå Image bundle download failed (outcome: ${{ steps.download-images.outcome }}), building containers locally..."

        # Check workspace state before building
        echo "Checking workspace state before container build..."
        df -h  # Check disk space
        echo "Ensuring clean Go module state..."
        go mod tidy

        # Build containers with explicit error handling
        set -euo pipefail
        echo "Building containers for flavor: $FLAVOR"
        hack/publish_containers.sh build "$FLAVOR"

        # Verify some key images were built
        echo "Verifying container builds..."
        expected_images="flightctl-api flightctl-worker flightctl-db-setup"
        for img in $expected_images; do
          if podman images --format "{{.Repository}}" | grep -q "$img"; then
            echo "‚úÖ Found $img image"
          else
            echo "‚ùå WARNING: $img image not found after build"
          fi
        done

        # Create image bundle locally
        TAG="${{ steps.compute-tags.outputs.git_tag }}"
        mkdir -p artifacts
        BUNDLE_FILE="artifacts/flightctl-images-bundle.tar"

        echo "Creating local image bundle with baseline tags for E2E compatibility..."
        # Get list of locally built flightctl images with flavor prefix
        mapfile -t flavor_images < <(podman images --format "{{.Repository}}:{{.Tag}}" | grep "flightctl-.*:${FLAVOR}-" | grep -E "(latest|${TAG})" || true)

        if [ ${#flavor_images[@]} -eq 0 ]; then
          echo "ERROR: No local flightctl images found for flavor $FLAVOR"
          exit 1
        fi

        # Create baseline tags (what deployment expects) and bundle only those
        baseline_images=()
        for image in "${flavor_images[@]}"; do
          repo="${image%:*}"
          flavor_tag="${image#*:}"
          baseline_tag="${flavor_tag#${FLAVOR}-}"  # Remove flavor prefix
          baseline_image="${repo}:${baseline_tag}"

          echo "  Creating baseline tag: ${baseline_image}"
          podman tag "$image" "$baseline_image"
          baseline_images+=("$baseline_image")
        done

        echo "Bundling ${#baseline_images[@]} baseline-tagged images for deployment:"
        printf '  %s\n' "${baseline_images[@]}"
        podman save --format docker-archive -o "$BUNDLE_FILE" "${baseline_images[@]}"

        echo "Local image bundle created: $(ls -lh $BUNDLE_FILE)"
        echo "::endgroup::"

    - name: Build local helm chart if artifact not available
      if: steps.download-chart.outcome == 'failure'
      shell: bash
      env:
        FLAVOR: ${{ inputs.flavor }}
      run: |
        echo "::group::Building local helm chart for $FLAVOR"
        echo "‚ùå Helm chart download failed (outcome: ${{ steps.download-chart.outcome }}), building chart locally..."

        mkdir -p artifacts

        # Generate chart with correct flavor
        echo "Generating chart templates for FLAVOR=$FLAVOR..."
        cd deploy/helm
        FLAVOR="$FLAVOR" go run cmd/charttmpl/main.go
        cd ../..

        # Build and package chart with error checking
        TAG="${{ steps.compute-tags.outputs.helm_tag }}"
        echo "Building chart with tag: $TAG"

        set -euo pipefail
        echo "Building helm dependencies..."
        helm dependency build ./deploy/helm/flightctl

        echo "Packaging helm chart..."
        helm package ./deploy/helm/flightctl --version "$TAG" --app-version "v$TAG"

        # Move to expected location
        GENERATED_FILE="flightctl-${TAG}.tgz"
        if [ ! -f "$GENERATED_FILE" ]; then
          echo "‚ùå ERROR: Expected chart file not found: $GENERATED_FILE"
          echo "Available files:"
          ls -la *.tgz 2>/dev/null || echo "No .tgz files found"
          exit 1
        fi

        mv "$GENERATED_FILE" "artifacts/flightctl-chart.tgz"
        echo "‚úÖ Local helm chart built: $(ls -lh artifacts/flightctl-chart.tgz)"
        echo "::endgroup::"

    - name: Build local CLI if artifact not available
      if: steps.download-cli.outcome == 'failure'
      shell: bash
      run: |
        echo "::group::Building local CLI binary"
        echo "‚ùå CLI download failed (outcome: ${{ steps.download-cli.outcome }}), building locally..."

        # Check if workspace is clean before building
        echo "Checking workspace state before CLI build..."
        if [ -d "bin" ]; then
          echo "bin/ directory exists, cleaning old CLI binary..."
          rm -f bin/flightctl
        fi

        # Ensure we have a clean Go module state
        echo "Ensuring clean Go module state..."
        go mod tidy

        # Build CLI with explicit error handling
        echo "Building CLI binary..."
        set -euo pipefail
        make build-cli

        # Verify the build worked
        if [ ! -f "bin/flightctl" ]; then
          echo "‚ùå ERROR: CLI build completed but binary not found at bin/flightctl"
          echo "Contents of bin/ directory:"
          ls -la bin/ || echo "bin/ directory not found"
          exit 1
        fi

        # Copy to artifacts
        mkdir -p artifacts
        cp bin/flightctl artifacts/flightctl-linux-amd64

        echo "‚úÖ Local CLI built successfully: $(ls -lh artifacts/flightctl-linux-amd64)"
        echo "::endgroup::"

    - name: Setup CLI binary
      shell: bash
      run: |
        set -euo pipefail
        mkdir -p bin

        # Check if CLI artifact exists before trying to move it
        if [ -f "artifacts/flightctl-linux-amd64" ]; then
          mv artifacts/flightctl-linux-amd64 bin/flightctl
          chmod +x bin/flightctl
          echo "‚úÖ CLI binary ready at bin/flightctl (from artifacts)"
        else
          echo "‚ùå CLI artifact not found in artifacts/"
          echo "Available artifacts:"
          ls -la artifacts/ || echo "No artifacts directory"

          echo "CLI download outcome: ${{ steps.download-cli.outcome }}"
          if [ "${{ steps.download-cli.outcome }}" == "failure" ]; then
            echo "CLI download failed, but fallback build should have created the binary"
            if [ -f "bin/flightctl" ]; then
              echo "‚úÖ CLI binary ready at bin/flightctl (from fallback build)"
            else
              echo "‚ùå ERROR: CLI binary not found after fallback build failed"
              exit 1
            fi
          else
            echo "‚ùå ERROR: CLI download succeeded but artifact file missing"
            exit 1
          fi
        fi

    # ========== INITIALIZE KIND CLUSTER ==========
    - name: Create kind cluster
      shell: bash
      run: kind create cluster --config ${{ inputs.kind-config }}

    # ========== LOAD IMAGES INTO KIND ==========
    - name: Load backend images into kind
      shell: bash
      env:
        FLAVOR: ${{ inputs.flavor }}
      run: |
        set -euo pipefail
        echo "=== LOADING BACKEND IMAGES INTO KIND ==="
        echo "Artifact download outcome: ${{ steps.download-images.outcome }}"
        echo "Available artifacts:"
        ls -la artifacts/ || echo "No artifacts directory"

        # Find the actual bundle file (artifact contains original filename)
        BUNDLE_FILE=$(find artifacts/ -name "flightctl-images-bundle.tar" 2>/dev/null | head -n1)

        if [ -n "$BUNDLE_FILE" ] && [ -f "$BUNDLE_FILE" ]; then
          echo "‚úÖ Found bundle: $BUNDLE_FILE"
          echo "Bundle size: $(ls -lh "$BUNDLE_FILE")"
          echo "Loading bundle into kind..."
          kind load image-archive "$BUNDLE_FILE"
          echo "‚úÖ Backend images loaded successfully from bundle"

          echo "DEBUG: Images now in kind after bundle load:"
          docker exec kind-control-plane crictl images | grep flightctl || echo "‚ùå No flightctl images found after bundle load!"

          # CRITICAL FIX: Published artifacts have flavor-prefixed tags, but deployment expects baseline tags
          # Create baseline tags from the loaded flavor-prefixed images
          echo "üèóÔ∏è  CRITICAL FIX: Creating baseline tags from published flavor-prefixed images..."
          TAG="${{ steps.compute-tags.outputs.git_tag }}"
          FLAVOR="${{ inputs.flavor }}"

          # Get images that were just loaded (they have flavor prefix)
          echo "Searching for loaded images with pattern: flightctl-.*:${FLAVOR}-"
          mapfile -t loaded_images < <(docker exec kind-control-plane crictl images --no-trunc | grep "flightctl" | grep "${FLAVOR}-" | awk '{print $1":"$2}' || true)

          echo "Found ${#loaded_images[@]} flavor-prefixed images to retag:"
          for image in "${loaded_images[@]}"; do
            repo="${image%:*}"
            flavor_tag="${image#*:}"
            baseline_tag="${flavor_tag#${FLAVOR}-}"  # Remove flavor prefix
            baseline_image="${repo}:${baseline_tag}"

            echo "  Creating baseline tag: ${image} ‚Üí ${baseline_image}"
            # Pull image from kind, retag, and push back
            docker exec kind-control-plane ctr -n k8s.io images tag "${image}" "${baseline_image}" || true
          done

          echo "‚úÖ Baseline tags created for deployment compatibility"

          echo "DEBUG: Verifying baseline tags were created:"
          echo "Expected baseline images for deployment:"
          expected_services="api db-setup worker periodic alert-exporter alertmanager-proxy cli-artifacts"
          for service in $expected_services; do
            expected_baseline="quay.io/flightctl/flightctl-${service}:${TAG}"
            echo "  Expected: ${expected_baseline}"
            # Fix: Check for both service name AND tag in the same line
            if docker exec kind-control-plane crictl images | grep -q "flightctl-${service}.*${TAG}"; then
              echo "    ‚úÖ Found baseline tag"
            else
              echo "    ‚ùå Missing baseline tag"
              # Debug: show what we actually found
              echo "    Available images for ${service}:"
              docker exec kind-control-plane crictl images | grep "flightctl-${service}" || echo "      None found"
            fi
          done

          echo "DEBUG: All images now in kind after baseline tag creation:"
          docker exec kind-control-plane crictl images | grep flightctl | head -20
        else
          echo "‚ùå No bundle found, attempting fallback to individual local images..."
          # Load individual images built locally
          TAG="${{ steps.compute-tags.outputs.git_tag }}"

          echo "üîç FALLBACK: Searching for local images with pattern: flightctl-.*:${FLAVOR}-*"
          echo "Expected tag components: FLAVOR=${FLAVOR}, TAG=${TAG}"

          # Debug: show ALL local images first
          echo "DEBUG: All local images:"
          podman images --format "{{.Repository}}:{{.Tag}}" | head -20

          # Get list of locally built flightctl images with flavor prefix
          echo "DEBUG: Searching for flavor-prefixed images..."
          mapfile -t flavor_images < <(podman images --format "{{.Repository}}:{{.Tag}}" | grep "flightctl-.*:${FLAVOR}-" | grep -E "(latest|${TAG})" || true)

          echo "DEBUG: Found ${#flavor_images[@]} flavor-prefixed images:"
          printf '  %s\n' "${flavor_images[@]}"

          if [ ${#flavor_images[@]} -eq 0 ]; then
            echo "‚ùå ERROR: No local flightctl images found for loading into kind"
            echo "Available local flightctl images:"
            podman images --format "{{.Repository}}:{{.Tag}}" | grep "flightctl" || echo "No flightctl images found"
            echo "Available ALL images:"
            podman images
            exit 1
          fi

          # Create and load baseline tags (what deployment expects)
          echo "üèóÔ∏è  Creating baseline tags for E2E deployment compatibility..."
          baseline_images=()
          for image in "${flavor_images[@]}"; do
            repo="${image%:*}"
            flavor_tag="${image#*:}"
            baseline_tag="${flavor_tag#${FLAVOR}-}"  # Remove flavor prefix
            baseline_image="${repo}:${baseline_tag}"

            echo "  Creating baseline tag: ${image} ‚Üí ${baseline_image}"
            podman tag "$image" "$baseline_image"

            echo "  Loading into kind: ${baseline_image}"
            kind load docker-image "$baseline_image"
            baseline_images+=("$baseline_image")
          done

          echo "‚úÖ Loaded ${#baseline_images[@]} baseline-tagged images for deployment"

          echo "DEBUG: Images now in kind after individual load:"
          docker exec kind-control-plane crictl images | grep flightctl || echo "‚ùå No flightctl images found after individual load!"
        fi

    - name: Clean up backend bundle files
      shell: bash
      run: |
        set -euo pipefail
        echo "::group::Cleaning up backend bundle files"
        echo "Removing backend bundle (no longer needed after loading into kind)..."
        BUNDLE_FILE=$(find artifacts/ -name "flightctl-images-bundle.tar" 2>/dev/null | head -n1)
        if [ -n "$BUNDLE_FILE" ] && [ -f "$BUNDLE_FILE" ]; then
          rm "$BUNDLE_FILE"
          echo "Removed: $BUNDLE_FILE"
        fi
        df -h
        echo "::endgroup::"

    - name: Setup dependencies
      uses: ./.github/actions/setup-dependencies

    - name: Generate helm charts with correct flavor
      shell: bash
      env:
        FLAVOR: ${{ inputs.flavor }}
      run: |
        set -euo pipefail
        echo "Generating helm charts with FLAVOR=${FLAVOR}"
        make generate

    # ========== DEPLOY BACKEND ==========
    - name: Deploy FlightCtl backend with Helm
      id: helm-deploy
      shell: bash
      env:
        BASE_DOMAIN: ${{ inputs.base-domain }}
        ADDITIONAL_VALUES_FILES: ${{ inputs.additional-values-files }}
        AUTH_TYPE: ${{ inputs.auth-type }}
        NAMESPACE_EXTERNAL: ${{ inputs.namespace-external }}
        NAMESPACE_INTERNAL: ${{ inputs.namespace-internal }}
        WAIT: ${{ inputs.wait }}
      run: |
        echo "üöÄ STARTING DEPLOY STEP - DEBUG CHECKPOINT 1"
        echo "Environment variables:"
        echo "  BASE_DOMAIN: ${BASE_DOMAIN}"
        echo "  NAMESPACE_EXTERNAL: ${NAMESPACE_EXTERNAL}"
        echo "  NAMESPACE_INTERNAL: ${NAMESPACE_INTERNAL}"
        echo "  WAIT: ${WAIT}"
        echo "  ADDITIONAL_VALUES_FILES: ${ADDITIONAL_VALUES_FILES}"
        echo "  AUTH_TYPE: ${AUTH_TYPE}"

        set -euo pipefail
        echo "üöÄ DEBUG CHECKPOINT 2 - pipefail enabled"

        kubectl create namespace "${NAMESPACE_INTERNAL}" || true
        echo "üöÄ DEBUG CHECKPOINT 3 - namespace created"

        ( kubectl get pods --all-namespaces -w | sed 's/^/[cluster] /' ) &
        echo "üöÄ DEBUG CHECKPOINT 4 - pod watcher started"

        # Simple cleanup - no fancy stuff
        echo "=== SIMPLE CLEANUP ==="
        set +e
        helm uninstall flightctl -n "${NAMESPACE_EXTERNAL}" --ignore-not-found --timeout=30s 2>/dev/null
        helm uninstall flightctl -n "${NAMESPACE_INTERNAL}" --ignore-not-found --timeout=30s 2>/dev/null
        kubectl delete namespace "${NAMESPACE_EXTERNAL}" --ignore-not-found --timeout=30s 2>/dev/null
        kubectl delete namespace "${NAMESPACE_INTERNAL}" --ignore-not-found --timeout=30s 2>/dev/null
        sleep 5
        kubectl create namespace "${NAMESPACE_INTERNAL}" 2>/dev/null || true
        set -e
        echo "=== CLEANUP COMPLETE ==="

        echo "REACHED HELM PREPARATION SUCCESSFULLY"

        # Build optional args - simplified
        EXTRA_ARGS=""
        if [ -n "${ADDITIONAL_VALUES_FILES}" ]; then
          for f in ${ADDITIONAL_VALUES_FILES}; do
            if [ -f "$f" ]; then
              EXTRA_ARGS+=" --values $f"
            fi
          done
        fi
        if [ -n "${AUTH_TYPE}" ]; then
          EXTRA_ARGS+=" --set global.auth.type=${AUTH_TYPE}"
        fi
        echo "EXTRA_ARGS: ${EXTRA_ARGS}"

        echo "=== STARTING HELM DEPLOYMENT ==="
        echo "Nuclear cleanup complete, verified clean state"
        echo "Images loaded and verified in kind"

        # Use baseline tags for E2E testing (consistent with our image loading)
        IMAGE_TAG="${{ steps.compute-tags.outputs.git_tag }}"
        echo "Using baseline image tag for E2E testing: ${IMAGE_TAG}"

        echo "Deployment parameters:"
        echo "  Base domain: ${BASE_DOMAIN}"
        echo "  External namespace: ${NAMESPACE_EXTERNAL}"
        echo "  Internal namespace: ${NAMESPACE_INTERNAL}"
        echo "  Wait for completion: ${WAIT}"
        echo "  Flavor: ${{ inputs.flavor }}"

        # Debug: Show what images are available in kind vs what we expect
        echo "=== IMAGE DEBUGGING ==="
        echo "Expected image tag: ${IMAGE_TAG}"
        echo "Expected FlightCtl images in kind cluster:"
        expected_services="api db-setup worker periodic alert-exporter alertmanager-proxy cli-artifacts telemetry-gateway imagebuilder-api imagebuilder-worker"
        for service in $expected_services; do
          expected_image="quay.io/flightctl/flightctl-${service}:${IMAGE_TAG}"
          echo "  Expected: ${expected_image}"
        done

        echo ""
        echo "ACTUAL FlightCtl images in kind cluster:"
        docker exec kind-control-plane crictl images | grep "flightctl" || echo "‚ùå No flightctl images found in kind!"

        echo ""
        echo "ALL images in kind cluster:"
        docker exec kind-control-plane crictl images | head -15

        # Set tags for ALL services including dbSetup (critical for init containers)
        EXTRA_ARGS+=" --set dbSetup.image.tag=${IMAGE_TAG}"
        EXTRA_ARGS+=" --set api.image.tag=${IMAGE_TAG}"
        EXTRA_ARGS+=" --set worker.image.tag=${IMAGE_TAG}"
        EXTRA_ARGS+=" --set periodic.image.tag=${IMAGE_TAG}"
        EXTRA_ARGS+=" --set alertExporter.image.tag=${IMAGE_TAG}"
        EXTRA_ARGS+=" --set alertmanagerProxy.image.tag=${IMAGE_TAG}"
        EXTRA_ARGS+=" --set cliArtifacts.image.tag=${IMAGE_TAG}"
        EXTRA_ARGS+=" --set telemetryGateway.image.tag=${IMAGE_TAG}"
        EXTRA_ARGS+=" --set imageBuilderApi.image.tag=${IMAGE_TAG}"
        EXTRA_ARGS+=" --set imageBuilderWorker.image.tag=${IMAGE_TAG}"

        # Set image pull policy to use local images when artifacts were not available
        if [ "${{ steps.download-images.outcome }}" == "failure" ]; then
          echo "Using local images - setting imagePullPolicy to IfNotPresent"
          EXTRA_ARGS+=" --set global.imagePullPolicy=IfNotPresent"
          EXTRA_ARGS+=" --set db.builtin.image.pullPolicy=IfNotPresent"
          EXTRA_ARGS+=" --set kv.image.pullPolicy=IfNotPresent"
          EXTRA_ARGS+=" --set alertmanager.image.pullPolicy=IfNotPresent"
          EXTRA_ARGS+=" --set clusterCli.image.pullPolicy=IfNotPresent"
        else
          echo "Using published images - keeping default imagePullPolicy"
        fi

        echo "üîç DEBUG: Looking for helm chart file..."
        echo "Available artifacts:"
        ls -la artifacts/ || echo "No artifacts directory found"

        # Find the actual chart file (artifact contains original filename)
        CHART_FILE=$(find artifacts/ -name "flightctl-chart.tgz" | head -n1)
        if [ -z "$CHART_FILE" ]; then
          echo "‚ùå ERROR: flightctl-chart.tgz not found in artifacts"
          echo "Contents of artifacts directory:"
          find artifacts/ -type f || echo "No files found"
          exit 1
        fi
        echo "‚úÖ Using chart file: $CHART_FILE (size: $(ls -lh "$CHART_FILE"))"

        echo "üîç DEBUG: Building helm command..."

        # Build the helm command
        HELM_CMD="helm install flightctl $CHART_FILE"
        HELM_CMD+=" --namespace ${NAMESPACE_EXTERNAL}"
        HELM_CMD+=" --create-namespace"

        # Check if values file exists
        if [ -f "deploy/helm/flightctl/values.nodeport.yaml" ]; then
          HELM_CMD+=" --values deploy/helm/flightctl/values.nodeport.yaml"
          echo "‚úÖ Using values file: deploy/helm/flightctl/values.nodeport.yaml"
        else
          echo "‚ùå Warning: deploy/helm/flightctl/values.nodeport.yaml not found"
          echo "Available files in deploy/helm/flightctl/:"
          ls -la deploy/helm/flightctl/ || echo "Directory not found"
        fi

        HELM_CMD+=' --set global.baseDomain="${BASE_DOMAIN}"'
        HELM_CMD+=" --set global.internalNamespace=${NAMESPACE_INTERNAL}"
        HELM_CMD+=" --set ui.enabled=false"
        HELM_CMD+="${EXTRA_ARGS}"

        if [ "${WAIT}" == "true" ]; then
          HELM_CMD+=" --wait"
          echo "‚úÖ Wait enabled - will wait for deployment completion"
        else
          echo "‚è≠Ô∏è  Wait disabled - will not wait for deployment completion"
        fi

        echo "üîç DEBUG: Final helm command: ${HELM_CMD}"

        # Output command for summary (with literal ${BASE_DOMAIN} for local reproduction)
        {
          echo "helm_cmd<<EOF"
          echo "${HELM_CMD}"
          echo "EOF"
        } >> "$GITHUB_OUTPUT"

        echo "*** ABOUT TO EXECUTE HELM INSTALL ***"
        echo "Command: ${HELM_CMD}"

        set +e  # Allow command to fail so we can debug
        if [ "${WAIT}" == "true" ]; then
          eval "${HELM_CMD} --debug"
          helm_exit_code=$?
        else
          eval "${HELM_CMD}"
          helm_exit_code=$?
        fi
        set -e

        echo "Helm install exit code: ${helm_exit_code}"
        if [ ${helm_exit_code} -ne 0 ]; then
          echo "‚ùå HELM INSTALL FAILED"
          echo "Checking helm status:"
          helm list -A || true
          echo "Checking for any created resources:"
          kubectl get all -A | grep flightctl || echo "No flightctl resources found"

          # Still exit with failure but after debugging
          exit ${helm_exit_code}
        else
          echo "‚úÖ HELM INSTALL SUCCEEDED"
        fi

        # Summary of deployment approach
        echo ""
        echo "=== DEPLOYMENT SUMMARY ==="
        echo "- Deployment type: Clean install (ensures fresh state)"
        if [ "${{ steps.download-images.outcome }}" == "failure" ]; then
          echo "- Source: LOCAL FALLBACK builds (artifacts not available)"
          echo "- Image tags: Baseline format for E2E compatibility"
          echo "- Image pull policy: IfNotPresent"
        else
          echo "- Source: PUBLISHED ARTIFACTS from workflow"
          echo "- Image pull policy: default"
        fi
        echo "- Image tag: ${IMAGE_TAG}"
        echo "- Flavor: ${{ inputs.flavor }}"
        echo "=========================="

    - name: "Debug deployment failures"
      if: failure()
      shell: bash
      run: |
        echo "=== DEBUGGING DEPLOYMENT FAILURE ==="
        echo "Cluster state:"
        kubectl get pods --all-namespaces --show-labels | grep flightctl || echo "No flightctl pods found"
        echo ""
        echo "Failed deployments:"
        kubectl get deployments --all-namespaces --show-labels | grep flightctl || echo "No flightctl deployments found"
        echo ""
        echo "Pod events for non-ready pods:"
        kubectl get pods --all-namespaces -l 'flightctl.service' --field-selector status.phase!=Running -o name 2>/dev/null | while read pod; do
          if [ -n "$pod" ]; then
            echo "=== Events for $pod ==="
            kubectl describe "$pod" 2>/dev/null | tail -20 || echo "Pod not found or already deleted"
            echo ""
          fi
        done
        echo ""
        echo "=== DEPLOYMENT FAILURE DEBUG ==="
        echo "Expected tag: ${{ steps.compute-tags.outputs.git_tag }}"
        echo "Flavor: ${{ inputs.flavor }}"
        echo "Artifact download outcome: ${{ steps.download-images.outcome }}"
        echo ""
        echo "Critical images check (‚úÖ=found, ‚ùå=missing):"
        for service in api db-setup worker periodic alert-exporter alertmanager-proxy; do
          image_name="quay.io/flightctl/flightctl-${service}"
          tag="${{ steps.compute-tags.outputs.git_tag }}"
          # Fix: Use a more robust check that accounts for crictl output format
          # crictl images format: IMAGE_NAME spaces TAG spaces IMAGE_ID spaces SIZE
          if docker exec kind-control-plane crictl images | grep "flightctl-${service}" | grep -q "${tag}"; then
            echo "  ‚úÖ ${image_name}:${tag}"
          else
            echo "  ‚ùå ${image_name}:${tag} (MISSING)"
          fi
        done
        echo ""
        echo "ALL FlightCtl images in kind:"
        docker exec kind-control-plane crictl images | grep flightctl || echo "‚ùå NO FLIGHTCTL IMAGES FOUND"
        echo ""
        echo "Helm release status:"
        helm list --all-namespaces
        echo "=== END DEBUGGING ==="

    - name: "Wait for API readiness"
      if: inputs.wait == 'true'
      uses: ./.github/actions/wait-for-api-readiness
      with:
        base-domain: ${{ inputs.base-domain }}

    - name: Generate deployment summary
      if: inputs.display-summary == 'true'
      shell: bash
      env:
        IMAGE_TAG: ${{ steps.compute-tags.outputs.git_tag }}
        NAMESPACE_EXTERNAL: ${{ inputs.namespace-external }}
        NAMESPACE_INTERNAL: ${{ inputs.namespace-internal }}
        KIND_CONFIG: ${{ inputs.kind-config }}
        RUN_ID: ${{ github.run_id }}
        HELM_CMD: ${{ steps.helm-deploy.outputs.helm_cmd }}
      run: |
        set -euo pipefail
        
        {
          echo "### :rocket: Deployment"
          echo ""
          echo "Backend deployed successfully to kind cluster."
          echo ""
          echo "#### Reproduce Locally"
          echo ""
          echo '```bash'
          echo "# Download artifacts"
          echo "mkdir -p bin artifacts"
          echo "gh run download ${RUN_ID} -n flightctl-images-bundle-${{ inputs.flavor }}-${IMAGE_TAG} -D bin"
          echo "gh run download ${RUN_ID} -n helm-chart-${{ inputs.flavor }}-${IMAGE_TAG} -D artifacts"
          echo ""
          echo "# Create kind cluster and load images"
          echo "kind create cluster --config ${KIND_CONFIG}"
          echo "kind load image-archive artifacts/flightctl-images-bundle.tar"
          echo ""
          echo "# Deploy (clean install)"
          echo 'source ./test/scripts/functions && export BASE_DOMAIN=$(get_ext_ip).nip.io'
          echo "# Clean up any existing installation first"
          echo "helm uninstall flightctl -n ${NAMESPACE_EXTERNAL} --wait || true"
          echo "kubectl delete namespace ${NAMESPACE_EXTERNAL} ${NAMESPACE_INTERNAL} --timeout=60s || true"
          echo "kubectl create namespace ${NAMESPACE_INTERNAL}"
          echo "${HELM_CMD}"
          echo '```'
        } >> "$GITHUB_STEP_SUMMARY"

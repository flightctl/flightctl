name: 'Deploy Backend with Helm'
description: |
  Complete deployment of FlightCtl backend to a kind cluster using Helm.
  
  Downloads artifacts (images, chart, CLI), creates kind cluster, loads images,
  and deploys using helm.

inputs:
  tag:
    description: 'Image tag for artifacts (if not provided, will be computed from git)'
    required: false
  base-domain:
    description: 'Base domain for the deployment'
    required: true
  namespace-external:
    description: 'External namespace for FlightCtl API components'
    required: false
    default: 'flightctl-external'
  namespace-internal:
    description: 'Internal namespace for FlightCtl backend components'
    required: false
    default: 'flightctl-internal'
  additional-values-files:
    description: 'Space-separated list of additional Helm values files to apply (paths relative to repo root)'
    required: false
    default: ''
  auth-type:
    description: 'Authentication type (empty for default, "k8s" for Kubernetes auth)'
    required: false
    default: ''
  kind-config:
    description: 'Path to kind cluster config file'
    required: false
    default: 'deploy/kind.yaml'
  display-summary:
    description: 'Whether to display deployment summary in GitHub step summary'
    required: false
    default: 'true'
  wait:
    description: 'Wait for deployment to complete (adds --wait --debug to helm install)'
    required: false
    default: 'true'
  flavor:
    description: 'Container flavor (el9 or el10)'
    required: false
    default: 'el9'

runs:
  using: "composite"
  steps:
    # ========== COMPUTE TAGS IF NOT PROVIDED ==========
    - name: Compute tags from git
      id: compute-tags-git
      if: inputs.tag == ''
      uses: ./.github/actions/compute-tag

    - name: Set git tag
      id: compute-tags
      shell: bash
      run: |
        set -euo pipefail
        
        if [ -n "${{ inputs.tag }}" ]; then
          echo "Using provided tag: ${{ inputs.tag }}"
          echo "git_tag=${{ inputs.tag }}" >> "$GITHUB_OUTPUT"
        else
          echo "Using computed git_tag: ${{ steps.compute-tags-git.outputs.git_tag }}"
          echo "git_tag=${{ steps.compute-tags-git.outputs.git_tag }}" >> "$GITHUB_OUTPUT"
        fi

    # ========== DOWNLOAD BACKEND ARTIFACTS ==========
    - name: Download backend images bundle
      id: download-images
      continue-on-error: true
      uses: actions/download-artifact@v4
      with:
        name: flightctl-images-bundle-${{ inputs.flavor }}-${{ steps.compute-tags.outputs.git_tag }}
        path: artifacts

    - name: Download helm chart
      id: download-chart
      continue-on-error: true
      uses: actions/download-artifact@v4
      with:
        name: helm-chart-${{ inputs.flavor }}-${{ steps.compute-tags.outputs.git_tag }}
        path: artifacts

    - name: Download CLI binary
      id: download-cli
      continue-on-error: true
      uses: actions/download-artifact@v4
      with:
        name: flightctl-linux-amd64-${{ inputs.flavor }}-${{ steps.compute-tags.outputs.git_tag }}
        path: artifacts

    # ========== FALLBACK: BUILD LOCAL ARTIFACTS IF DOWNLOADS FAILED ==========
    - name: Build local containers if artifacts not available
      if: steps.download-images.outcome == 'failure'
      shell: bash
      env:
        FLAVOR: ${{ inputs.flavor }}
      run: |
        set -euo pipefail
        echo "::group::Building local containers for $FLAVOR"
        echo "Image bundle download failed, building containers locally..."

        # Build all containers for the specified flavor
        hack/publish_containers.sh build "$FLAVOR"

        # Create image bundle locally
        TAG="${{ steps.compute-tags.outputs.git_tag }}"
        mkdir -p artifacts
        BUNDLE_FILE="artifacts/flightctl-images-bundle.tar"

        echo "Creating local image bundle with baseline tags for E2E compatibility..."
        # Get list of locally built flightctl images with flavor prefix
        mapfile -t flavor_images < <(podman images --format "{{.Repository}}:{{.Tag}}" | grep "flightctl-.*:${FLAVOR}-" | grep -E "(latest|${TAG})" || true)

        if [ ${#flavor_images[@]} -eq 0 ]; then
          echo "ERROR: No local flightctl images found for flavor $FLAVOR"
          exit 1
        fi

        # Create baseline tags (what deployment expects) and bundle only those
        baseline_images=()
        for image in "${flavor_images[@]}"; do
          repo="${image%:*}"
          flavor_tag="${image#*:}"
          baseline_tag="${flavor_tag#${FLAVOR}-}"  # Remove flavor prefix
          baseline_image="${repo}:${baseline_tag}"

          echo "  Creating baseline tag: ${baseline_image}"
          podman tag "$image" "$baseline_image"
          baseline_images+=("$baseline_image")
        done

        echo "Bundling ${#baseline_images[@]} baseline-tagged images for deployment:"
        printf '  %s\n' "${baseline_images[@]}"
        podman save --format docker-archive -o "$BUNDLE_FILE" "${baseline_images[@]}"

        echo "Local image bundle created: $(ls -lh $BUNDLE_FILE)"
        echo "::endgroup::"

    - name: Build local helm chart if artifact not available
      if: steps.download-chart.outcome == 'failure'
      shell: bash
      env:
        FLAVOR: ${{ inputs.flavor }}
      run: |
        set -euo pipefail
        echo "::group::Building local helm chart for $FLAVOR"
        echo "Helm chart download failed, building chart locally..."

        mkdir -p artifacts

        # Generate chart with correct flavor
        cd deploy/helm
        FLAVOR="$FLAVOR" go run cmd/charttmpl/main.go
        cd ../..

        # Build and package chart
        TAG="${{ steps.compute-tags.outputs.helm_tag }}"
        helm dependency build ./deploy/helm/flightctl
        helm package ./deploy/helm/flightctl --version "$TAG" --app-version "v$TAG"

        # Move to expected location
        GENERATED_FILE="flightctl-${TAG}.tgz"
        mv "$GENERATED_FILE" "artifacts/flightctl-chart.tgz"

        echo "Local helm chart built: $(ls -lh artifacts/flightctl-chart.tgz)"
        echo "::endgroup::"

    - name: Build local CLI if artifact not available
      if: steps.download-cli.outcome == 'failure'
      shell: bash
      run: |
        set -euo pipefail
        echo "::group::Building local CLI binary"
        echo "CLI download failed, building locally..."

        make build-cli
        mkdir -p artifacts
        cp bin/flightctl artifacts/flightctl-linux-amd64

        echo "Local CLI built: $(ls -lh artifacts/flightctl-linux-amd64)"
        echo "::endgroup::"

    - name: Setup CLI binary
      shell: bash
      run: |
        set -euo pipefail
        mkdir -p bin
        mv artifacts/flightctl-linux-amd64 bin/flightctl
        chmod +x bin/flightctl
        echo "CLI binary ready at bin/flightctl"

    # ========== INITIALIZE KIND CLUSTER ==========
    - name: Create kind cluster
      shell: bash
      run: kind create cluster --config ${{ inputs.kind-config }}

    # ========== LOAD IMAGES INTO KIND ==========
    - name: Load backend images into kind
      shell: bash
      env:
        FLAVOR: ${{ inputs.flavor }}
      run: |
        set -euo pipefail
        echo "Loading backend service images into kind"
        echo "Available artifacts:"
        ls -la artifacts/ || echo "No artifacts directory"

        # Find the actual bundle file (artifact contains original filename)
        BUNDLE_FILE=$(find artifacts/ -name "flightctl-images-bundle.tar" 2>/dev/null | head -n1)

        if [ -n "$BUNDLE_FILE" ] && [ -f "$BUNDLE_FILE" ]; then
          echo "Loading bundle: $BUNDLE_FILE"
          kind load image-archive "$BUNDLE_FILE"
          echo "Backend images loaded successfully from bundle"
        else
          echo "No bundle found, loading individual local images..."
          # Load individual images built locally
          TAG="${{ steps.compute-tags.outputs.git_tag }}"

          # Get list of locally built flightctl images with flavor prefix
          mapfile -t flavor_images < <(podman images --format "{{.Repository}}:{{.Tag}}" | grep "flightctl-.*:${FLAVOR}-" | grep -E "(latest|${TAG})" || true)

          if [ ${#flavor_images[@]} -eq 0 ]; then
            echo "ERROR: No local flightctl images found for loading into kind"
            echo "Available local images:"
            podman images --format "{{.Repository}}:{{.Tag}}" | grep "flightctl" || echo "No flightctl images found"
            exit 1
          fi

          # Create and load baseline tags (what deployment expects)
          echo "Creating baseline tags for E2E deployment compatibility..."
          baseline_images=()
          for image in "${flavor_images[@]}"; do
            repo="${image%:*}"
            flavor_tag="${image#*:}"
            baseline_tag="${flavor_tag#${FLAVOR}-}"  # Remove flavor prefix
            baseline_image="${repo}:${baseline_tag}"

            echo "  Creating and loading baseline tag: ${baseline_image}"
            podman tag "$image" "$baseline_image"
            kind load docker-image "$baseline_image"
            baseline_images+=("$baseline_image")
          done

          echo "Loaded ${#baseline_images[@]} baseline-tagged images for deployment"
        fi

    - name: Clean up backend bundle files
      shell: bash
      run: |
        set -euo pipefail
        echo "::group::Cleaning up backend bundle files"
        echo "Removing backend bundle (no longer needed after loading into kind)..."
        BUNDLE_FILE=$(find artifacts/ -name "flightctl-images-bundle.tar" 2>/dev/null | head -n1)
        if [ -n "$BUNDLE_FILE" ] && [ -f "$BUNDLE_FILE" ]; then
          rm "$BUNDLE_FILE"
          echo "Removed: $BUNDLE_FILE"
        fi
        df -h
        echo "::endgroup::"

    - name: Setup dependencies
      uses: ./.github/actions/setup-dependencies

    - name: Generate helm charts with correct flavor
      shell: bash
      env:
        FLAVOR: ${{ inputs.flavor }}
      run: |
        set -euo pipefail
        echo "Generating helm charts with FLAVOR=${FLAVOR}"
        make generate

    # ========== DEPLOY BACKEND ==========
    - name: Deploy FlightCtl backend with Helm
      id: helm-deploy
      shell: bash
      env:
        BASE_DOMAIN: ${{ inputs.base-domain }}
        ADDITIONAL_VALUES_FILES: ${{ inputs.additional-values-files }}
        AUTH_TYPE: ${{ inputs.auth-type }}
        NAMESPACE_EXTERNAL: ${{ inputs.namespace-external }}
        NAMESPACE_INTERNAL: ${{ inputs.namespace-internal }}
        WAIT: ${{ inputs.wait }}
      run: |
        set -euo pipefail

        kubectl create namespace "${NAMESPACE_INTERNAL}" || true
        ( kubectl get pods --all-namespaces -w | sed 's/^/[cluster] /' ) &

        # Force clean state for E2E testing - always uninstall first to avoid upgrade hooks
        echo "=== ENFORCING CLEAN INSTALL FOR E2E ==="

        # Uninstall any existing release (ignore errors if not found)
        echo "Removing any existing FlightCtl installation..."
        helm uninstall flightctl -n "${NAMESPACE_EXTERNAL}" --ignore-not-found --wait --timeout=5m || true
        helm uninstall flightctl -A --ignore-not-found || true  # Clean up any release in any namespace

        # Force delete namespaces immediately
        echo "Force deleting namespaces for clean state..."
        kubectl delete namespace "${NAMESPACE_EXTERNAL}" "${NAMESPACE_INTERNAL}" --ignore-not-found --timeout=30s --force --grace-period=0 || true

        # Brief wait and recreate
        echo "Waiting 10 seconds before recreating namespaces..."
        sleep 10

        # Recreate internal namespace (external created by helm install --create-namespace)
        kubectl create namespace "${NAMESPACE_INTERNAL}" || true
        echo "=== CLEAN INSTALL ENVIRONMENT READY ==="

        # Build optional args
        EXTRA_ARGS=""
        for f in ${ADDITIONAL_VALUES_FILES}; do [ -f "$f" ] && EXTRA_ARGS+=" --values $f"; done
        [ -n "${AUTH_TYPE}" ] && EXTRA_ARGS+=" --set global.auth.type=${AUTH_TYPE}"

        # Use baseline tags for E2E testing (consistent with our image loading)
        IMAGE_TAG="${{ steps.compute-tags.outputs.git_tag }}"
        echo "Using baseline image tag for E2E testing: ${IMAGE_TAG}"

        # Debug: Show what images are available in kind
        echo "Available FlightCtl images in kind cluster:"
        docker exec kind-control-plane crictl images | grep "flightctl" || echo "No flightctl images found"

        # Set tags for ALL services including dbSetup (critical for init containers)
        EXTRA_ARGS+=" --set dbSetup.image.tag=${IMAGE_TAG}"
        EXTRA_ARGS+=" --set api.image.tag=${IMAGE_TAG}"
        EXTRA_ARGS+=" --set worker.image.tag=${IMAGE_TAG}"
        EXTRA_ARGS+=" --set periodic.image.tag=${IMAGE_TAG}"
        EXTRA_ARGS+=" --set alertExporter.image.tag=${IMAGE_TAG}"
        EXTRA_ARGS+=" --set alertmanagerProxy.image.tag=${IMAGE_TAG}"
        EXTRA_ARGS+=" --set cliArtifacts.image.tag=${IMAGE_TAG}"
        EXTRA_ARGS+=" --set telemetryGateway.image.tag=${IMAGE_TAG}"
        EXTRA_ARGS+=" --set imageBuilderApi.image.tag=${IMAGE_TAG}"
        EXTRA_ARGS+=" --set imageBuilderWorker.image.tag=${IMAGE_TAG}"

        # Set image pull policy to use local images when artifacts were not available
        if [ "${{ steps.download-images.outcome }}" == "failure" ]; then
          echo "Using local images - setting imagePullPolicy to IfNotPresent"
          EXTRA_ARGS+=" --set global.imagePullPolicy=IfNotPresent"
          EXTRA_ARGS+=" --set db.builtin.image.pullPolicy=IfNotPresent"
          EXTRA_ARGS+=" --set kv.image.pullPolicy=IfNotPresent"
          EXTRA_ARGS+=" --set alertmanager.image.pullPolicy=IfNotPresent"
          EXTRA_ARGS+=" --set clusterCli.image.pullPolicy=IfNotPresent"
        else
          echo "Using published images - keeping default imagePullPolicy"
        fi

        # Find the actual chart file (artifact contains original filename)
        CHART_FILE=$(find artifacts/ -name "flightctl-chart.tgz" | head -n1)
        if [ -z "$CHART_FILE" ]; then
          echo "ERROR: flightctl-chart.tgz not found in artifacts"
          exit 1
        fi
        echo "Using chart file: $CHART_FILE"

        # Build the helm command
        HELM_CMD="helm install flightctl $CHART_FILE"
        HELM_CMD+=" --namespace ${NAMESPACE_EXTERNAL}"
        HELM_CMD+=" --create-namespace"
        HELM_CMD+=" --values deploy/helm/flightctl/values.nodeport.yaml"
        HELM_CMD+=' --set global.baseDomain="${BASE_DOMAIN}"'
        HELM_CMD+=" --set global.internalNamespace=${NAMESPACE_INTERNAL}"
        HELM_CMD+=" --set ui.enabled=false"
        HELM_CMD+="${EXTRA_ARGS}"

        if [ "${WAIT}" == "true" ]; then
          HELM_CMD+=" --wait"
        fi

        # Output command for summary (with literal ${BASE_DOMAIN} for local reproduction)
        {
          echo "helm_cmd<<EOF"
          echo "${HELM_CMD}"
          echo "EOF"
        } >> "$GITHUB_OUTPUT"

        # Execute with --debug for verbose output if waiting
        if [ "${WAIT}" == "true" ]; then
          eval "${HELM_CMD} --debug"
        else
          eval "${HELM_CMD}"
        fi

        # Summary of deployment approach
        echo ""
        echo "=== DEPLOYMENT SUMMARY ==="
        echo "- Deployment type: Clean install (ensures fresh state)"
        if [ "${{ steps.download-images.outcome }}" == "failure" ]; then
          echo "- Source: LOCAL FALLBACK builds (artifacts not available)"
          echo "- Image tags: Baseline format for E2E compatibility"
          echo "- Image pull policy: IfNotPresent"
        else
          echo "- Source: PUBLISHED ARTIFACTS from workflow"
          echo "- Image pull policy: default"
        fi
        echo "- Image tag: ${IMAGE_TAG}"
        echo "- Flavor: ${{ inputs.flavor }}"
        echo "=========================="

    - name: "Debug deployment failures"
      if: failure()
      shell: bash
      run: |
        echo "=== DEBUGGING DEPLOYMENT FAILURE ==="
        echo "Cluster state:"
        kubectl get pods --all-namespaces --show-labels | grep flightctl || echo "No flightctl pods found"
        echo ""
        echo "Failed deployments:"
        kubectl get deployments --all-namespaces --show-labels | grep flightctl || echo "No flightctl deployments found"
        echo ""
        echo "Pod events for non-ready pods:"
        kubectl get pods --all-namespaces -l 'flightctl.service' --field-selector status.phase!=Running -o name 2>/dev/null | while read pod; do
          if [ -n "$pod" ]; then
            echo "=== Events for $pod ==="
            kubectl describe "$pod" 2>/dev/null | tail -20 || echo "Pod not found or already deleted"
            echo ""
          fi
        done
        echo ""
        echo "Available images in kind:"
        docker exec kind-control-plane crictl images | grep flightctl || echo "No flightctl images found"
        echo ""
        echo "Expected image tag: ${{ steps.compute-tags.outputs.git_tag }}"
        echo "Flavor: ${{ inputs.flavor }}"
        echo ""
        echo "Key images expected by deployment:"
        for service in api db-setup worker periodic alert-exporter; do
          expected_image="quay.io/flightctl/flightctl-${service}:${{ steps.compute-tags.outputs.git_tag }}"
          if docker exec kind-control-plane crictl images | grep -q "${expected_image}"; then
            echo "  ✅ ${expected_image}"
          else
            echo "  ❌ ${expected_image}"
          fi
        done
        echo ""
        echo "Helm release status:"
        helm list --all-namespaces
        echo "=== END DEBUGGING ==="

    - name: "Wait for API readiness"
      if: inputs.wait == 'true'
      uses: ./.github/actions/wait-for-api-readiness
      with:
        base-domain: ${{ inputs.base-domain }}

    - name: Generate deployment summary
      if: inputs.display-summary == 'true'
      shell: bash
      env:
        IMAGE_TAG: ${{ steps.compute-tags.outputs.git_tag }}
        NAMESPACE_EXTERNAL: ${{ inputs.namespace-external }}
        NAMESPACE_INTERNAL: ${{ inputs.namespace-internal }}
        KIND_CONFIG: ${{ inputs.kind-config }}
        RUN_ID: ${{ github.run_id }}
        HELM_CMD: ${{ steps.helm-deploy.outputs.helm_cmd }}
      run: |
        set -euo pipefail
        
        {
          echo "### :rocket: Deployment"
          echo ""
          echo "Backend deployed successfully to kind cluster."
          echo ""
          echo "#### Reproduce Locally"
          echo ""
          echo '```bash'
          echo "# Download artifacts"
          echo "mkdir -p bin artifacts"
          echo "gh run download ${RUN_ID} -n flightctl-images-bundle-${{ inputs.flavor }}-${IMAGE_TAG} -D bin"
          echo "gh run download ${RUN_ID} -n helm-chart-${{ inputs.flavor }}-${IMAGE_TAG} -D artifacts"
          echo ""
          echo "# Create kind cluster and load images"
          echo "kind create cluster --config ${KIND_CONFIG}"
          echo "kind load image-archive artifacts/flightctl-images-bundle.tar"
          echo ""
          echo "# Deploy (clean install)"
          echo 'source ./test/scripts/functions && export BASE_DOMAIN=$(get_ext_ip).nip.io'
          echo "# Clean up any existing installation first"
          echo "helm uninstall flightctl -n ${NAMESPACE_EXTERNAL} --wait || true"
          echo "kubectl delete namespace ${NAMESPACE_EXTERNAL} ${NAMESPACE_INTERNAL} --timeout=60s || true"
          echo "kubectl create namespace ${NAMESPACE_INTERNAL}"
          echo "${HELM_CMD}"
          echo '```'
        } >> "$GITHUB_STEP_SUMMARY"
